[{"path":"index.html","id":"introduction","chapter":"Introduction","heading":"Introduction","text":"course designed completed approximately three weeks. first two weeks, several chapters workbook work asynchronously accompanying walkthrough video suggested reading list. time takes work chapter vary considerably depending previous experience R programming.still start journey R, estimate chapter may take 2-3 hours likely want need watch walkthrough video full. experience programming likely take less time included links resources can go beyond core material provided course. help planning, please note chapters data wrangling data tidying likely take time chapters data analysis.addition asynchronous content, two live office hour sessions Week 2 3. sessions, instructors answer questions content covered workbook apply using Us Researcher Workbench. Finally, complete course, 20-item multiple-choice quiz.","code":""},{"path":"index.html","id":"instructors","chapter":"Introduction","heading":"0.1 Instructors","text":"Dr. Emily Nordmann teaching-focused Senior Lecturer School Psychology Neuroscience University Glasgow. teaches research methods, individual differences data skills R well acting Deputy Director Education. vocal advocate open science open educational resources. member PsyTeachR team authored several open-access data skills books tutorials, also Communications Chair EdArXiv, preprint sever education research community. lives Glasgow, Scotland wife Kathleen cat Khaleesi, named final season Game Thrones aired.Dr. Javan K. Carter bioinformaticist RTI International. researches genomic transcriptomic data understand genotype- phenotype correlation genetic architecture complex traits diseases. Within RTI, lead co-lead informatics scientist several projects assists number projects associated various data types. also evolutionary genomicist training. uses bash, JavaScript, R primary coding languages. loves teach educate people wonders computational biology introduce people coding first time!","code":""},{"path":"index.html","id":"progress","chapter":"Introduction","heading":"0.2 Progress Tracker","text":"course designed completed approximately three weeks. help plan time keep track, provided Progress Tracker checklist details need need .Download Progress Tracker Word documentDownload Progress Tracker PDF","code":""},{"path":"index.html","id":"course-overview","chapter":"Introduction","heading":"0.3 Course Overview","text":"video gives overview course syllabus requirements. important watch video starting course.Download Course Overview PowerPoint slides","code":""},{"path":"prerequisites.html","id":"prerequisites","chapter":"1 Pre-requisites","heading":"1 Pre-requisites","text":"","code":""},{"path":"prerequisites.html","id":"skills","chapter":"1 Pre-requisites","heading":"1.1 Skills","text":"course assumes able :Install load packagesWrite code RMarkdown creating new document code chunksUse tidyverse functions perform simple data wrangling tasks, calculate descriptive statistics, produce data visualisations using ggplot()Recognize use pipe %>% function (although ok fully understand point)","code":""},{"path":"prerequisites.html","id":"software","chapter":"1 Pre-requisites","heading":"1.2 Software","text":"course assumes installed access R RStudio. Whilst use Us Researcher Workbench conduct analyses Us database, access regular copy R machine can use free--charge helpful learning R.Installing R RStudio usually straightforward. sections explain helpful YouTube video . run difficulties (example admin rights machine), recommend using RStudio Cloud. RStudio Cloud almost features local installation R runs browser. differences import export data manage projects cloud local installation, however, part differences minimal.yet R RStudio installed, instructions guide process.","code":""},{"path":"prerequisites.html","id":"intro-rstudio","chapter":"1 Pre-requisites","heading":"1.3 R and RStudio","text":"R programming language write code RStudio Integrated Development Environment (IDE) makes working R easier. Think knowing English using plain text editor like NotePad write book versus using word processor like Microsoft Word. , much harder without things like spell-checking formatting able use advanced features Word developed. similar way, can use R without R Studio (sometimes referred \"Base R\") recommend . RStudio serves text editor, file manager, spreadsheet viewer, . key thing remember although work using RStudio course, actually using two pieces software means time--time, may separate updates.","code":""},{"path":"prerequisites.html","id":"installing-base-r","chapter":"1 Pre-requisites","heading":"1.4 Installing Base R","text":"Install base R. Choose download link operating system (Linux, Mac OS X, Windows).Mac, install latest release newest R-x.x.x.pkg link (legacy version older operating system). may also need install XQuartz able use visualisation packages.installing Windows version, choose \"base\" subdirectory click download link top page.using Linux, choose specific operating system follow installation instructions.","code":""},{"path":"prerequisites.html","id":"installing-rstudio","chapter":"1 Pre-requisites","heading":"1.5 Installing RStudio","text":"Go rstudio.com download RStudio Desktop (Open Source License) version operating system list titled Installers Supported Platforms.","code":""},{"path":"prerequisites.html","id":"installing-rtools","chapter":"1 Pre-requisites","heading":"1.6 Installing RTools","text":"using Windows, install R, also install RTools; use \"recommended\" version highlighted near top list. RTools used installing loading packages. can get started without installing RTools, problems installing loading packages, first thing try.RTools require put \"PATH\". instructions can seem bit vague - easiest way open RStudio, run code console:done , restart R clicking Session - Restart R run code console give path RTools installation:","code":"\nwrite('PATH=\"${RTOOLS40_HOME}\\\\usr\\\\bin;${PATH}\"', file = \"~/.Renviron\", append = TRUE)\nSys.which(\"make\")##                               make \n## \"C:\\\\rtools40\\\\usr\\\\bin\\\\make.exe\""},{"path":"prerequisites.html","id":"rstudio-settings","chapter":"1 Pre-requisites","heading":"1.7 RStudio Settings","text":"settings fix immediately updating RStudio. Go Global Options... Tools menu (âŒ˜,), General tab, uncheck box says Restore .RData workspace startup. keep things around workspace, things get messy, unexpected things happen. always start clear workspace. also means never want save workspace exit, set Never. thing want save scripts.may also want change appearance code. Different fonts themes can sometimes help visual difficulties dyslexia.\nFigure 1.1: RStudio General Appearance settings\nmay also want change settings Code tab. example, people prefer two spaces instead tabs code, like able see whitespace characters. matter personal preference.\nFigure 1.2: RStudio Code settings\n","code":""},{"path":"prerequisites.html","id":"installing-latex","chapter":"1 Pre-requisites","heading":"1.8 Installing LaTeX","text":"can install LaTeX typesetting system produce PDF reports RStudio. Without additional installation, able produce reports HTML PDF. generate PDF reports, additionally need install tinytex (Xie, 2022) run following code:Please note producing PDF reports necessary learn R complete course, trouble step, can skip return comfortable R (decide PDF reports useful).","code":"\n# run this in the console\ninstall.packages(\"tinytex\")\ntinytex::install_tinytex()"},{"path":"prerequisites.html","id":"updating-r","chapter":"1 Pre-requisites","heading":"1.9 Updating R, RStudio, and packages","text":"time--time, updated versions R, RStudio, packages use (e.g., ggplot) become available. Remember separate, different process come different considerations. recommend updating latest version start new project. definitely recommend updating middle project middle semester bring advice based personal experience pain.","code":""},{"path":"prerequisites.html","id":"updating-rstudio","chapter":"1 Pre-requisites","heading":"1.10 Updating RStudio","text":"RStudio easiest component update. Typically, updates RStudio affect code, instead add new features, like spell-check upgrades RStudio can . usually little downside updating RStudio easy .Click Help - Check updates\nFigure 1.3: Updating RStudio\nupdate available, prompt download can install usual.","code":""},{"path":"prerequisites.html","id":"updating-r-1","chapter":"1 Pre-requisites","heading":"1.11 Updating R","text":"Finally, may also wish update R . key thing aware update R, just download latest version website, lose packages.","code":""},{"path":"prerequisites.html","id":"windows","chapter":"1 Pre-requisites","heading":"1.11.1 Windows","text":"easiest way update R Windows cause huge headache use installr package. use updateR() function, series dialogue boxes appear. fairly self-explanatory full step--step guide available use installr, important bit select \"Yes\" asked like copy packages older version R.","code":"\n# Install the installr package\ninstall.packages(\"installr\")\n\n# Run the update function\ninstallR::updateR()"},{"path":"prerequisites.html","id":"mac","chapter":"1 Pre-requisites","heading":"1.11.2 Mac","text":"Mac, can use updateR package. need install GitHub. asked type system password (use log computer) console pane. relevant, ask want restore packages new major version.","code":"\n# install from github\ndevtools::install_github(\"AndreaCirilloAC/updateR\")\n\n# update your R version, you will need your system password\nupdateR::updateR()"},{"path":"prerequisites.html","id":"updating-packages","chapter":"1 Pre-requisites","heading":"1.12 Updating packages","text":"Package developers occasionally release updates packages. typically add new functions package, fix amend existing functions. aware package updates may cause previous code stop working. tend happen minor updates packages, occasionally major updates, can serious issues developer made fundamental changes code works. reason, recommend updating packages beginning academic year (semester) - assessment deadline just case!update individual package, easiest way use install.packages() function, always installs recent version package.update multiple packages, indeed packages, RStudio provides helpful tools. Click Tools - Check Package Updates. dialogue box appear can select packages wish update. aware select packages, may take time unable use R whilst process completes.\nFigure 1.4: Updating packages RStudio\n","code":"\ninstall.packages(\"tidyverse\")"},{"path":"prerequisites.html","id":"package-install-troubleshooting","chapter":"1 Pre-requisites","heading":"1.13 Troubleshooting","text":"Occasionally, might problem packages seemingly refuse update install. Emily, rlang vctrs cause end trouble. packages likely ever explicitly load, required beneath surface R things like knit Markdown files etc.","code":""},{"path":"prerequisites.html","id":"non-zero-exit-status","chapter":"1 Pre-requisites","heading":"1.13.1 Non-zero exit status","text":"try update package get error message says something like Warning install.packages : installation package â€˜vctrsâ€™ non-zero exit status perhaps Error loadNamespace(, c(lib.loc, .libPaths()), versionCheck = vI[[]]) :  namespace 'rlang' 0.4.9 loaded, >= 0.4.10 required one solution found manually uninstall package, restart R, install package new, rather trying update existing version. installr package also useful function uninstalling packages.","code":"\n# Load installr\nlibrary(installr)\n\n# Uninstall the problem package\nuninstall.packages(\"package_name\")\n\n# Then restart R using session - restart R\n# Then install the package fresh\n\ninstall.packages(\"package\")"},{"path":"prerequisites.html","id":"cannot-open-file","chapter":"1 Pre-requisites","heading":"1.13.2 Cannot open file","text":"may get following error trying install packages :Error install packages : open file 'C:/.....': Permission deniedThis usually indicates permissions problem writing default library (folder packages kept ). Sometimes means need install R RStudio administrator run administrator.One fix may change library location using following code (check \"C:/Program Files/R\" version instead \"R-3.5.2\"):works can install packages, set library path permanently:Install usethis packageRun usethis::edit_r_profile() console; open blank filePaste file (version ): .libPaths(c(\"C:/Program Files/R/R-3.5.2/library\"))Save close fileRestart R changes take effectThe code .Rprofile now run every time start R.","code":"\n# change the library path\n.libPaths(c(\"C:/Program Files/R/R-3.5.2/library\"))"},{"path":"prerequisites.html","id":"rstudio-cloud","chapter":"1 Pre-requisites","heading":"1.13.3 RStudio Cloud","text":"recommend local installation R RStudio, least means need active internet connection use . However, difficulty installing R, Rstudio, next chapter, packages, strongly recommend using RStudio Cloud runs browser. purposes course, little difference learning local installation using cloud. matters get running feel comfortable set-, installation issues, take break, use RStudio Cloud instead, return installation later point.","code":""},{"path":"wrangle.html","id":"wrangle","chapter":"2 Data wrangling","heading":"2 Data wrangling","text":"","code":""},{"path":"wrangle.html","id":"ilo-wrangle","chapter":"2 Data wrangling","heading":"2.1 Intended Learning Outcomes","text":"end chapter able :Select filter data relevanceCreate new columns edit existing onesHandle missing data","code":""},{"path":"wrangle.html","id":"walkthrough-wrangle","chapter":"2 Data wrangling","heading":"2.2 Walkthrough video","text":"encourage read workbook attempt step watching video help consolidate learning (may feel harder making mistakes informative help learn long-run).","code":""},{"path":"wrangle.html","id":"setup-wrangle","chapter":"2 Data wrangling","heading":"2.3 Set-up","text":"Create new project course following:Create save new R Markdown document named chapter_2.Rmd, get rid default template text line 11 onwards.Add code set-chunk run code load packages data.may need install packages installed already.Download Data transformation cheat sheet","code":"\nlibrary(tidyverse)   \nlibrary(medicaldata)\ndata(\"opt\")\ndata(\"polyps\")"},{"path":"wrangle.html","id":"wrangling-functions","chapter":"2 Data wrangling","heading":"2.4 Wrangling functions","text":"Data wrangling refers process cleaning, transforming, restructuring data get format need analysis something spend awful lot time . worth highlighting chapter going cover common functions common uses said functions. However, dplyr (packages beyond ) huge number additional wrangling functions function many different arguments. Essentially, think able wrangle data particular way explicitly shown , almost certainly can, might just take bit Googling find .going use polyps opt datasets. can learn datasets using help function:","code":"\n?medicaldata::opt\n?medicaldata::polyps"},{"path":"wrangle.html","id":"select","chapter":"2 Data wrangling","heading":"2.4.1 Select","text":"can select subset columns (variables) table make easier view prepare table display. can also select columns new order.","code":""},{"path":"wrangle.html","id":"by-name-or-index","chapter":"2 Data wrangling","heading":"2.4.1.1 By name or index","text":"can select columns name number (sometimes referred column index). Selecting number can useful column names long complicated. opt dataset huge number variables (171 total) likely might need .can select column individually, separated commas can also select columns one another separating colon. colon notation can much faster need type individual variable name, make sure know order columns always check output make sure selected intended.can rename columns time selecting setting new_name = old_col.","code":"\n# select columns by name\nopt_select <- opt %>% select(Clinic, Age, Education) \n\n# select columns by number\nopt_select <- opt %>% select(2, 3, 10) \n# select columns individually\nopt_multiple <- opt %>% select(PID, Clinic, Group, Age)\n\n# select columns with colon\nopt_multiple <- opt %>% select(PID:Age)\nopt_rename <- opt %>% select(PID, Location = Clinic, Black:Hisp)\n\nhead(opt_rename, 2)"},{"path":"wrangle.html","id":"de-selecting-columns","chapter":"2 Data wrangling","heading":"2.4.1.2 De-selecting columns","text":"can select columns either telling R ones want keep previous examples, specifying ones want exclude using minus symbol de-select columns. can also use colon notation de-select columns, need put parentheses around span first, e.g., -(Black:Hisp), -Black:Hisp.","code":"\n# de-select individual columns\nopt_deselect <- opt_rename %>% select(-Location)\n\n# de-select a range of columns\nopt_deselect2 <- opt_rename %>% select(-(Black:Hisp))"},{"path":"wrangle.html","id":"select-helpers","chapter":"2 Data wrangling","heading":"2.4.1.3 Select helpers","text":"Finally, can select columns based criteria column names, example:","code":""},{"path":"wrangle.html","id":"filter","chapter":"2 Data wrangling","heading":"2.4.2 Filter","text":"Whilst select() chooses columns want retain, filter() chooses rows retain matching row column criteria.can filter single criterion. criterion can rows certain column's value matches character value (e.g., \"NY\") number (e.g., 20). can also result logical equation (e.g., keep rows specific column value larger certain value). criterion checked row, result FALSE, row removed. can reverse equations specifying != ! means \"\".Remember use == = check two things equivalent. single = assigns right-hand value left-hand variable (much like <- operator).IDs kept table ?demo %>% filter(score < 80)\n1, 2233, 4demo %>% filter(grade == \"\")\n1, 2233, 4demo %>% filter(grade != \"\")\n1, 2233, 4demo %>% filter(score == 91)\n1, 2233, 4You can also select multiple criteria separating commas (rows kept match criteria). Additionally, can use & (\"\") | (\"\") create complex criteria.want filter retain multiple specific values variable, match operator (%%) used rather | (). ! can also used combination , placed variable name.filter() incredibly powerful can allow select specific subsets data. , also quite dangerous start combining multiple criteria operators, easy accidentally specify something slightly different intended. Always check output. small dataset, can eyeball see looks right. larger dataset, may wish compute summary statistics count number groups/observations variable verify filter correct. level expertise coding can substitute knowing checking data.","code":"\n# select all rows where clinic equals NY\nopt %>% filter(Clinic == \"NY\")\n\n# select all rows where Age is exactly equal to 20\nopt %>% filter(Age == 20)\n\n# select all rows where Age was more than 20\nopt %>% filter(Age > 20)\n\n# everything but NY\nopt %>% filter(Clinic != \"NY\")\n# patients with a BMI equal to or above 30 AND who have diabetes\nbmi_diabetes <- opt %>% \n  filter(\n    Diabetes == \"Yes\",\n    BMI >= 30\n  )\n\n# the same as above, using & instead of a comma\nbmi_diabetes <- opt %>% \n  filter(\n    Diabetes == \"Yes\" &\n    BMI >= 30\n  )\n\n# patients with a BMI above or equal to 30 OR who have diabetes\ndiabetes_either <- opt %>% \n  filter(\n    Diabetes == \"Yes\" |\n    BMI >= 30\n  )\n# retain any rows where Clinic is NY or MN or KY, and where Black equals yes\nopt %>%\n  filter(Clinic %in% c(\"NY\", \"MN\", \"KY\"),\n         Black == \"Yes\")\n\n# retain any rows where the region is not NY or MN or KY, and where Black does not equal Yes\nopt %>%\n  filter(!Clinic %in% c(\"NY\", \"MN\", \"KY\"),\n         Black != \"Yes\")"},{"path":"wrangle.html","id":"arrange","chapter":"2 Data wrangling","heading":"2.4.3 Arrange","text":"can sort dataset using arrange(). find needing sort data R much less Excel, since need rows next order , example, calculate group means. arrange() can useful preparing data display tables. arrange() works character data sort alphabetically, well numeric data default ascending order (smallest largest). Reverse order using desc().","code":"\n# arranging the table \n# first by sex in alphabetical order\n# then by \"baseline\" in descending order\npolyps %>%\n  arrange(sex, desc(baseline)) "},{"path":"wrangle.html","id":"mutate","chapter":"2 Data wrangling","heading":"2.4.4 Mutate","text":"function mutate() allows add new columns change existing ones overwriting using syntax new_column = operation. can add one column mutate function separating columns comma. make new column, can use column definitions.example, polyps dataset contains data number polyps baseline, 3 months treatment, 12 months treatment. can create treatment1 treatment2 tell us improvement number polyps two treatment milestones (negative number good thing, means fewer polyps baseline), use new variables create total.look dataset, see total contains NAs (missing values), come back soon.mutate() can also used conjunction functions Boolean operators. example, can add another column polyps2 states whether improvement number polyps seen overwrite treatment variable factor. Just like used Boolean expressions filter, evaluate equation return TRUE FALSE depending whether observation meets criteria.can overwrite column giving new column name old column (see treatment) . Make sure mean trying use old column value redefine .can also use case_when() specify values return, rather defaulting TRUE FALSE:Use recode values:combine different criteria:Just like filter(), mutate() incredibly powerful scope can create far beyond can cover book.","code":"\npolyps2 <- polyps %>%\n  mutate(\n    treatment1 = number3m - baseline ,\n    treatment2 = number12m - number3m,\n    total = treatment1 + treatment2,\n    treatment  = paste(treatment , \"condition\")\n  )\npolyps2 <- polyps2 %>%\n  mutate(improvement = total < 0,\n         treatment = as.factor(treatment))\npolyps3 <- polyps2 %>%\n  mutate(improvement = case_when(total > 0 ~ \"Decline\",\n                                 total == 0 ~ \"No change\",\n                                 total < 0 ~ \"Improvement\"))\n# create a column of categories depending on number of polyps\n\npolyps4 <- polyps3 %>%\n  mutate(category = case_when(baseline <= 10 ~ \"Low\",\n                              baseline > 10 & baseline <= 30 ~ \"Medium\",\n                              baseline > 30 ~ \"High\"))\n# patients are categorized as high if they have a high number of polyps if they are male and under 25\n\npolyps5 <- polyps4 %>%\n  mutate(risk = case_when(category == \"High\" ~ \"High risk\",\n                          sex == \"Male\" & age < 25 ~ \"High risk\",\n                          TRUE ~ \"Not high risk\")) # set all other values to \"no bonus\""},{"path":"wrangle.html","id":"descriptive-statistics","chapter":"2 Data wrangling","heading":"2.5 Descriptive statistics","text":"","code":""},{"path":"wrangle.html","id":"count","chapter":"2 Data wrangling","heading":"2.5.1 Count","text":"useful simple function count(). count() return number unique values one variables - likely use categorical/factor variable also work numeric data. can count total number observations dataset:number observations grouping variable:can also use count multiple grouping variables. example, look number male female participants (specified assume sex assigned birth) treatment condition. Note order specify variables affect layout resulting table (can never visualize order need specify variables - best advice run code, look output, edit needed).code produces number male female patients treatmentWhilst code produced number treatment condition sex assigned birth:","code":"\n# total number of observations (rows) in the dataset\npolyps5 %>%\n  count()\n# total number in each treatment condition\npolyps5 %>%\n  count(treatment)\npolyps5 %>%\n  count(treatment, sex)\npolyps5 %>%\n  count(sex, treatment)"},{"path":"wrangle.html","id":"dplyr-summarise","chapter":"2 Data wrangling","heading":"2.5.2 Summarise","text":"summarise() applies summary functions entire table (groups, see next section). However, go much need deal pesky missing values.say want determine mean, median, min max number polyps treatment. function summarise() allows us create table column names left-hand value (.e.g, mean_polyps) values result operation right-hand side (e.g., take mean() variable total).problem dataset missing values produces table full NAs:Whilst can seem unintuitive R return number, makes logical sense - average 100 \"know\" 100, \"know\". ways can deal understanding data knowing missing crucial.","code":"\npolyps5 %>%\n  summarise(\n    mean_polyps = mean(total),\n    median_polyps = median(total),\n    min_polyps = min(total),\n    max_polyps = max(total)\n  )"},{"path":"wrangle.html","id":"missing-values","chapter":"2 Data wrangling","heading":"2.5.3 Missing values","text":"First, get stats exactly much missing data - going go back using original polyps dataset loaded rather later ones created original missing data cause problems..na() evaluates whether value cell NA simply adds many values return NA column.actually two missing values 12 month column enough caused us big problems line. calculated treatment, treatment2, total simply added subtracted variables , ignoring missing values replicated new variable used :three options dealing . One option use complete dataset remove rows NA using drop_na() function. new dataset polyps6 20 observations dropped two participants missing data number12m column:second option tell R ignore missing values calculations. use polyps5 dataset first created missing values time run summarise(), add na.rm = TRUE means \"remove NAs calculation\". useful addition summarise() going use na.rm = TRUE call n = n() essentially thing count() tells many observations used calculation helps ensure accidentally calculate summary data lots missing observations without realising :Finally, also replace NA values another value. example, datasets might appropriate replace missing data 0 mean. Neither actually appropriate dataset show code anyway:Missing data can quite difficult deal depending represented. always, amount coding expertise can make understanding structure idiosyncrasies data.","code":"\npolyps %>%\n  summarise(\n    missing_baseline = sum(is.na(baseline)),\n    missing_3m = sum(is.na(number3m)),\n    missing_12m = sum(is.na(number12m))\n  )\npolyps5 %>%\n    summarise(\n    missing_treatment1 = sum(is.na(treatment1)),\n    missing_treatment2 = sum(is.na(treatment2)),\n    missing_total = sum(is.na(total))\n  )\npolyps6 <- polyps %>%\n  drop_na(number12m) %>%\n  mutate(treatment1 = number3m - baseline ,\n    treatment2 = number12m - number3m,\n    total = treatment1 + treatment2)\n\npolyps6 %>%\n  summarise(\n    mean_polyps = mean(total),\n    median_polyps = median(total),\n    min_polyps = min(total),\n    max_polyps = max(total)\n  )\npolyps6 %>%\n  summarise(\n    mean_polyps = mean(total, na.rm = TRUE),\n    median_polyps = median(total, na.rm = TRUE),\n    min_polyps = min(total, na.rm = TRUE),\n    max_polyps = max(total, na.rm = TRUE),\n    n = n()\n  )\n# replace NAs with 0\npolyps7 <- polyps %>%\n  mutate(number12m = replace_na(number12m, 0))%>%\n  mutate(treatment1 = number3m - baseline ,\n    treatment2 = number12m - number3m,\n    total = treatment1 + treatment2)\n\n# replace NAs with the mean of the 12m column\npolyps8 <- polyps %>%\n  mutate(number12m = replace_na(number12m, mean(number12m, na.rm = TRUE)))%>%\n  mutate(treatment1 = number3m - baseline ,\n    treatment2 = number12m - number3m,\n    total = treatment1 + treatment2)"},{"path":"wrangle.html","id":"dplyr-groupby","chapter":"2 Data wrangling","heading":"2.5.4 Group By","text":"already used group_by() times worth introducing formally. group_by() groups dataset whatever function performed dataset done separately level grouping variable. group_by() makes easy look different combinations variables:can also use group_by() combination functions. example, slice_max() returns top N rows, ordered specific variable. example, return three patients largest reduction polyps.can combined group_by() return largest reductions treatment:","code":"\n# by one grouping variable (sex)\n\npolyps5 %>%\n  group_by(sex) %>%\n  summarise(mean = mean(total, na.rm = TRUE))\n\n# by two grouping variables\n\npolyps5 %>%\n  group_by(sex, treatment) %>%\n  summarise(mean = mean(total, na.rm = TRUE))\n\n# order of the variables affects the layout of the table produced\n\npolyps5 %>%\n  group_by(treatment, sex) %>%\n  summarise(mean = mean(total, na.rm = TRUE))\n# return top 3 sales\npolyps5 %>%\n  slice_max(n = 3, order_by = desc(total))\n# return top sale for each region\npolyps5 %>%\n  group_by(treatment) %>%\n  slice_max(n = 3, order_by = desc(total))"},{"path":"wrangle.html","id":"complications","chapter":"2 Data wrangling","heading":"2.6 Complications","text":"","code":""},{"path":"wrangle.html","id":"rounding","chapter":"2 Data wrangling","heading":"2.6.1 Rounding","text":"purposes exercise going switch back opt gum disease dataset need data decimal form.First, just round one variable one decimal place.BL.PD.avg whole-mouth average pocket depth baseline (mm).Looks fairly simple, , quirk rounding R important know . filter values 2.5, 3.5 4.5 round values whole number:look values spot 2.5 rounded 2, 3.5 rounded 4, 4.5 rounded 4. may seem like mistake, R rounds .5 nearest even number, rather always , like probably taught school. prevents overestimation biases, since x.5 exactly halfway x x+1, reason always round .However, might throw monkey wrench systems. example, University Glasgow, policy round course marks x.5. One solution define version round() (modified Andrew Landgraf's blog). Put hidden code block top script, clear warning changing way round() normally works. need understand function works, just use .run code, new section appear environment pane labelled \"Functions\". addition using functions packages, can also make . something going go detail course, useful know functionality exists.Now round() work expect.Just remove version want R go back original method. Remember define new round method script uses , run definition code use interactively. can check Environment pane see whether round listed \"Functions\".","code":"\nopt2 <- opt %>%\n  select(BL.PD.avg) %>%\n  mutate(BL.PD.avg.1 = round(BL.PD.avg, 1), # round to one decimal place\n         BL.PD.avg.whole = round(BL.PD.avg)) # round to whole number\nopt3 <- opt2 %>%\n  filter(BL.PD.avg.1 %in% c(1.5, 2.5, 3.5, 4.5)) %>%\n  mutate(BL.PD.avg.whole = round(BL.PD.avg.1))\nround(0.5)\nround(1.5)## [1] 0\n## [1] 2\n#!!!!!! redefining round so 5s round up !!!!!! \nround <- function(x, digits = 0) {\n  posneg = sign(x)\n  z = abs(x)*10^digits\n  z = z + 0.5 + sqrt(.Machine$double.eps)\n  z = trunc(z)\n  z = z/10^digits\n  z*posneg\n}\nround(0.5)\nround(1.5)## [1] 1\n## [1] 2\n# remove new round() method\nrm(round)"},{"path":"wrangle.html","id":"exercise","chapter":"2 Data wrangling","heading":"2.7 Exercise","text":"help consolidate learned chapter, use dataset familiar replicate functions gone chapter. Additionally, try identifying steps data cleaning wrangling process typically need perform see can find necessary functions arguments needed . looking help online, may find useful append \"r dplyr\" search, example, \"rename column r dplyr\" likely return results use tidyverse style code used course.","code":""},{"path":"wrangle.html","id":"glossary-wrangle","chapter":"2 Data wrangling","heading":"2.8 Glossary","text":"","code":""},{"path":"wrangle.html","id":"resources-wrangle","chapter":"2 Data wrangling","heading":"2.9 Further resources","text":"Data transformation cheat sheetChapter 5: Data Transformation R Data ScienceChapter 19: Functions R Data ScienceIntroduction stringr","code":""},{"path":"tidy.html","id":"tidy","chapter":"3 Data Tidying","heading":"3 Data Tidying","text":"","code":""},{"path":"tidy.html","id":"ilo-tidy","chapter":"3 Data Tidying","heading":"3.1 Intended Learning Outcomes","text":"end chapter able :Reshape data long wide formatsUse pipes chain together functions","code":""},{"path":"tidy.html","id":"walkthrough-tidy","chapter":"3 Data Tidying","heading":"3.2 Walkthrough video","text":"encourage read workbook attempt step watching video help consolidate learning (may feel harder making mistakes informative help learn long-run).","code":""},{"path":"tidy.html","id":"setup-tidy","chapter":"3 Data Tidying","heading":"3.3 Set-up","text":"Create save new R Markdown document named chapter_3.Rmd, get rid default template text line 11 onwards.Add code set-chunk run code load packages data.may need install packages installed already.Download Data tidying cheat sheet.","code":"\nlibrary(tidyverse) \nlibrary(medicaldata)\ndata(\"polyps\")\ndata(\"theoph\")\ndata(\"laryngoscope\")"},{"path":"tidy.html","id":"data-structures","chapter":"3 Data Tidying","heading":"3.4 Data Structures","text":"data work likely come many different formats structures. structures may driven software use outputs data, data structures may also differ human intervention attempts organisation, may particularly helpful.Data cleaning tidying likely time consuming difficult task perform. Whilst can create code recipes analyses visualisations, Hadley Whickham puts , \"every messy dataset messy way\", means often solve new problems specific dataset. Additionally, moving data structures intuitive read humans useful computer requires conceptual shift comes practice.verbose way saying lies ahead chapter unlikely sink first attempt need practice different examples (preferably data know well) truly feel comfortable .First, terminology.observation information single \"thing\" single condition, one point time. things can patients, sales, participants, feedback questionnaires, really anything. Observations way identify , unique ID unique combination values like ID time-pointA variable one type information observation. example, observation participant, variables might participant participant ID, participant's sex age, condition experiment , score.value data one variable one observation. example, value age variable observation participant might 23.dataset theoph loaded set-study looking anti-asthma medication. 12 participants given dose medication whose plasma tested 11 different time points (can read full details running help documentation ?theoph). look dataset answer following questions:Time? ObservationVariableValueHow many observations dataset? 79.6? ObservationVariableValueTime type information dataset. five variables, Subject, Wt, Dose, Time conc.132 observations, 11 12 participants different time points.79.6 value single data point one variable one observation.","code":""},{"path":"tidy.html","id":"reshaping-data","chapter":"3 Data Tidying","heading":"3.5 Reshaping Data","text":"Data tables can wide format long format (mix two). Wide data observations one thing row, long data observation separate row. often need convert formats different types summaries visualisation. may done something similar using pivot tables Excel.\nFigure 3.1: Converting wide long formats using pivot tables Excel.\n","code":""},{"path":"tidy.html","id":"wide-format-data","chapter":"3 Data Tidying","heading":"3.5.1 Wide-format data","text":"polyps dataset used previous chapter example wide-form dataset. observations participant row. participant data three time-points (baseline, number3m, number12m) stored three separate columnsWhilst wide-form data easy read, sometimes obfuscates many variables actually dataset observations spread columns. look polyps dataset think many variables thinking variables type information, rather column:many variables (types information) polyps dataset? six variables. Four relatively straightforward: participant_id, sex, age, treatment. final two gets complicated. three columns baseline, number3m, number12m actually represent two bits information, number polyps (call polyps_n), time-point (timepoint).","code":""},{"path":"tidy.html","id":"tidy-data","chapter":"3 Data Tidying","heading":"3.5.2 Tidy data","text":"Whilst wide-form data intuitive humans read enter data , can also little difficult work R. Instead, often need use \"tidy data long-form 1, data format makes easier combine data different tables, create summary tables, visualise data.observation must rowEach variable must columnEach value must cellWe've already seen example tidy data - theoph dataset easy way spot multiple rows data Subject rather observations spread across columns single row:tidy version polyps dataset look like :now six variables (columns) six different types information observation: participant id, sex, age, treatment condition, time point measurement, measurement (number polyps).row participant's polyp measurement particular time-point.pivot functions allow transform data table wide long long wide.","code":""},{"path":"tidy.html","id":"wide-to-long","chapter":"3 Data Tidying","heading":"3.5.3 Wide to long","text":"function pivot_longer() converts wide data table longer format converting headers specified columns values new columns, combining values columns new condensed column.function several arguments:cols: columns want make long; can refer names, like c(\"baseline\", \"number3m\", \"number12m\") numbers, like c(4, 6, 7)names_to: want call new columns cols column header names go intovalues_to: want call new column contains values colsWith pivot functions, can easier show tell - run code compare polyps polyps_tidy pivot code try map argument changed.long-form dataset makes possible use tidyverse functions flexibly summarise visualise dataset. example, wide-form dataset, order calculate mean number polyps time-point, need specify calculation time-point individually:However, tidy version, code become concise (therefore less error-prone) also means additional time-points added dataset, code need change: return calculation groups.added benefit tidy datasets work well ggplot (plot quite tricky create wide-form dataset):experimental researchers, may find easier remember IV DV column, rather column level IV.","code":"\npolyps_tidy <- polyps %>%\n  pivot_longer(cols = c(\"baseline\", \"number3m\", \"number12m\"), # columns to make long \n               names_to = \"time\", # new column name for headers\n               values_to = \"polyps_n\") # new column name for values\npolyps %>%\n  summarise(mean_baseline = mean(baseline),\n            mean_3m = mean(number3m),\n            mean_12m = mean(number12m, na.rm = TRUE))\npolyps_tidy %>%\n  group_by(time) %>%\n  summarise(mean = mean(polyps_n, na.rm = TRUE))\nggplot(polyps_tidy, aes(x = polyps_n, fill = time)) +\n  geom_histogram(show.legend = F, colour = \"black\") +\n  facet_wrap(~time, nrow = 3) +\n  scale_fill_viridis_d(option = \"E\") +\n  theme_minimal()"},{"path":"tidy.html","id":"long-to-wide","chapter":"3 Data Tidying","heading":"3.5.4 Long to wide","text":"Whilst long-form data practically essential working R (particularly rely heavily tidyverse), times need wide-form dataset. original dataset long-form, can also go long wide format using pivot_wider() function.id_cols: column(s) uniquely identify new rownames_from: column(s) contain new column headers, variable want spread widervalues_from: column contains values new columnsAgain, easier show tell run code compare polyps_tidy polys_wide (look like original polyps dataset).\nTable 3.1: Data made wider pivot_wider()\nexample wide-format data required needed create scatterplot conduct correlation two levels grouping variable need data separate columns:","code":"\npolyps_wide <- polyps_tidy %>%\n  pivot_wider(\n  id_cols = c(\"participant_id\", \"sex\", \"age\", \"treatment\"), # identifying column(s)\n  names_from = time, # the new column names\n  values_from = polyps_n # the new column values\n)\npolyps_wide %>%\n  filter(baseline < 200) %>% # remove the outliers\n  ggplot(aes(x = baseline, y = number12m, colour = treatment)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")"},{"path":"tidy.html","id":"multistep","chapter":"3 Data Tidying","heading":"3.6 Multi-step tidying","text":"Restructuring data wide long-form arguably one difficult tasks need whilst coding, nature problem depends design study idiosyncrasies dataset organisation, interaction two. , run another example, time slightly complicated dataset require us create intermediate objects.example, going use laryngoscope dataset intubation methods - recommend reviewing help documentation familiarize variables go (?laryngoscope). dataset quite large going reduce number variables just need example:","code":"\nlaryn_subset <- laryngoscope %>%\n  select(age, gender, Randomization:attempt3_S_F)"},{"path":"tidy.html","id":"adding-id-variables","chapter":"3 Data Tidying","heading":"3.6.1 Adding ID variables","text":"dataset originally participant ID codes. likely wide-form know data points relate participant row, however, start pulling apart putting data back together, can prevent number issues ensure clear ID column observations belong thing.add ID number, use mutate() create column ID number equals row number. also move first column dataset using select() everything() selects id column, everything else dataset.","code":"\nlaryn_subset <- laryn_subset %>%\n  mutate(id = row_number()) %>%\n  select(id, everything())"},{"path":"tidy.html","id":"untidy-long-form","chapter":"3 Data Tidying","heading":"3.6.2 Untidy long-form","text":"think variables dataset now. First, uncomplicated ones:id, age, gender, RandomizationWe eight columns different information intubation attempts. Whilst eight columns, really four different types information, variables:attempt attempt number intubation, 1-3time intubation attempt time secondssuccess whether intubation attempt successfulmethod method used intubation attemptLet's try code used transform previous, simpler dataset:right - got multiple different types information variable score columns. First, separate attempt measurement. somewhat straightforward information attempt always left first underscore variable name (e.g., attempt1_time), can use argument names_sep tell R split column underscore put data side two columns named attempt measurement.control data, key reason consistent naming conventions super important. consistent meaningful uses capital letters, underscores, periods variable names, can use information manipulate data frames far easily. laryn dataset used underscores separate names bits information (e.g., attempt1_time) also used generic spaces (e.g., attempt2_assignment_method).means tidy dataset names_sep argument, get warning message:asked R separate variables underscore given two column names, discarded information comes second underscore. actually make great deal difference dataset, labeling still relatively meaningful:However, like precise control separation, can use names_pattern argument. (.*?)_(.*) uses two groups data first group everything first underscore ((.*?)) column name second group everything underscore following first group ((.*)) (Thank Stack Overflow solution!).","code":"\nlaryn_tidy1 <- laryn_subset %>%\n  pivot_longer(cols = starts_with(\"attempt\"), #tidy all variables that start with \"attempt\"\n               names_to = \"variable\", \n               values_to = \"score\")\nhead(laryn_tidy1)\nlaryn_tidy2 <- laryn_subset %>%\n  pivot_longer(cols = c(attempt1_time:attempt3_S_F),\n               names_sep = \"_\",\n               names_to = c(\"attempt\", \"measurement\"), \n               values_to = \"score\")## Warning: Expected 2 pieces. Additional pieces discarded in 5 rows [2, 4, 5, 7,\n## 8].\nlaryn_tidy3 <- laryn_subset %>%\n  pivot_longer(cols = c(attempt1_time:attempt3_S_F),\n               names_pattern = '(.*?)_(.*)',\n               names_to = c(\"attempt\", \"measurement\"), \n               values_to = \"score\")"},{"path":"tidy.html","id":"spreading-variables-to-create-tidy-data","chapter":"3 Data Tidying","heading":"3.6.3 Spreading variables to create tidy data","text":"still quite right whilst sorted names, score variable contains three different types measurement (intubation time, whether success failure, assignment method). Instead need additional step spread measurements across different variables:Technically, can skip setting id_cols argument, columns apart names_from column values_from column identify observation (e.g., observation identified unique combination id, age, gender etc). set id_cols argument case although can useful exercise help ensure understand structure data.","code":"\nlaryn_tidy4 <- laryn_tidy3 %>%\n  pivot_wider(id_cols = c(\"id\", \"age\", \"gender\", \"Randomization\", \"attempt\"),\n              names_from = \"measurement\", \n              values_from = \"score\")"},{"path":"tidy.html","id":"correcting-factors","chapter":"3 Data Tidying","heading":"3.6.4 Correcting factors","text":"Finally, can also tidy categorical variables: gender, Randomization S_F represented numerical data actually categories. just tell R data factor leave values :might well take opportunity make dataset readable. great thing working R everything coded numerically e.g., SPSS. Instead, can use text labels means remember 0 1 means.Now data finally tidy format can use tidyverse functions easily summarize visualize different variables.example, can calculate average intubation time attempt:visualize numberof success failures attempt:","code":"\nstr(laryn_tidy4)\n\nlaryn_tidy5 <- laryn_tidy4 %>%\n  mutate(gender = as.factor(gender),\n         Randomization = as.factor(Randomization),\n         S_F = as.factor(S_F))\n\nstr(laryn_tidy5)\nlaryn_tidy6 <- laryn_tidy4 %>%\n  mutate(gender = factor(gender, \n                         levels = c(0,1),\n                         labels = c(\"female\", \"male\")),\n    Randomization = factor(Randomization, \n                                levels = c(0,1), \n                                labels = c(\"Standard\", \"AWS\")),\n         S_F = factor(S_F, \n                      levels = c(0,1), \n                      labels = c(\"failure\", \"success\")))\n\nstr(laryn_tidy6)\nlaryn_tidy6 %>%\n  group_by(attempt) %>%\n  summarise(mean_time =mean(time, na.rm = TRUE))\nlaryn_tidy6 %>%\n  filter(!is.na(S_F)) %>% # remove NAs from plot\n  ggplot(aes(x = S_F)) +\n  geom_bar() +\n  facet_wrap(~ attempt)"},{"path":"tidy.html","id":"pipes","chapter":"3 Data Tidying","heading":"3.7 Pipes","text":"used pipes %>% throughout course type data processing really start shine, can significantly reduce amount code write.recap, pipe takes result previous function sends next function first argument, means need create intermediate objects. code used chapter, process created multiple objects. can get confusing longer scripts.can give object name keep replacing old data object new one step. keep environment clean, makes debugging code much harder.longer series steps like one , using pipes can eliminate many intermediate objects. also makes easier add intermediate step process without think new table name edit table input next step (really easy accidentally miss).can read code like :Start dataset laryngoscope thenStart dataset laryngoscope thenSelect columns interested select() thenSelect columns interested select() thenAdd ID column mutate() thenAdd ID column mutate() thenMove ID column start dataset select() thenMove ID column start dataset select() thenReshape data longer pivot_longer() thenReshape data longer pivot_longer() thenReshape data wider pivot_wider() thenReshape data wider pivot_wider() thenSet categorical variables factors using mutate() factor() update text labels.Set categorical variables factors using mutate() factor() update text labels.feel like always need get data wrangling code single pipeline. make intermediate objects whenever need break code getting complicated need debug something.can debug pipe highlighting beginning just pipe want stop . Try highlighting laryn_tidy <- end pivot_longer function (just next pipe) typing command-enter (mac) control-enter (PC). laryn_tidy look like now?","code":"\n# read in data\ndata(\"laryngoscope\")\n\n# select subset of data\nlaryn_subset <- laryngoscope %>%\n  select(age, gender, Randomization:attempt3_S_F)\n\n# add ID column\nlaryn_subset <- laryn_subset %>%\n  mutate(id = row_number()) %>%\n  select(id, everything())\n\n# create untidy long-form data\nlaryn_tidy3 <- laryn_subset %>%\n  pivot_longer(cols = c(attempt1_time:attempt3_S_F),\n               names_pattern = '(.*?)_(.*)',\n               names_to = c(\"attempt\", \"measurement\"), \n               values_to = \"score\")\n\n# finalise tidy data by spreading variables\nlaryn_tidy4 <- laryn_tidy3 %>%\n  pivot_wider(id_cols = c(\"id\", \"age\", \"gender\", \"Randomization\", \"attempt\"),\n              names_from = \"measurement\", \n              values_from = \"score\")\n\n\n# correct factors\nlaryn_tidy6 <- laryn_tidy4 %>%\n  mutate(gender = factor(gender, \n                         levels = c(0,1),\n                         labels = c(\"female\", \"male\")),\n    Randomization = factor(Randomization, \n                                levels = c(0,1), \n                                labels = c(\"Standard\", \"AWS\")),\n         S_F = factor(S_F, \n                      levels = c(0,1), \n                      labels = c(\"failure\", \"success\")))\ndata(\"laryngoscope\")\n\nlaryn_tidy <-  laryngoscope %>%\n  select(age, gender, Randomization:attempt3_S_F) %>%\n  mutate(id = row_number()) %>%\n  select(id, everything()) %>%\n  pivot_longer(cols = c(attempt1_time:attempt3_S_F),\n               names_pattern = '(.*?)_(.*)',\n               names_to = c(\"attempt\", \"measurement\"), \n               values_to = \"score\") %>%\n  pivot_wider(id_cols = c(\"id\", \"age\", \"gender\", \"Randomization\", \"attempt\"),\n              names_from = \"measurement\", \n              values_from = \"score\")%>%\n  mutate(gender = factor(gender, \n                         levels = c(0,1),\n                         labels = c(\"female\", \"male\")),\n    Randomization = factor(Randomization, \n                                levels = c(0,1), \n                                labels = c(\"Standard\", \"AWS\")),\n         S_F = factor(S_F, \n                      levels = c(0,1), \n                      labels = c(\"failure\", \"success\")))"},{"path":"tidy.html","id":"exercises","chapter":"3 Data Tidying","heading":"3.8 Exercises","text":"noted, reshaping data one difficult tasks learn every dataset different. help practice, examples can work .set-code chunk, load tidyverse load two data files using read_csv() name objects wide1 wide2The two datasets represent simulated data patient satisfaction survey. one time, differ complexity.","code":"\nlibrary(tidyverse)\nwide1 <- read_csv(\"https://psyteachr.github.io/ads-v1/data/wide_exercise-1.csv\")\nwide2 <- read_csv(\"https://psyteachr.github.io/ads-v1/data/wide_exercise-2.csv\")"},{"path":"tidy.html","id":"survey-1","chapter":"3 Data Tidying","heading":"3.8.1 Survey 1","text":"wide1 data 50 patients asked five questions recent experience health centre. results questionnaire typically reported single overall satisfaction score, calculated taking mean five responses. Additionally, survey also records whether patient attending clinic first time, repeat patient.Use method choice look dataset familiarise structure data.can click object view viewing pane use following:noted, important think tidied data look like. Often, problem data wrangling R actually code, lack understanding data worked .many variables long-form version wide ? many observations long-form version wide1 ? four variables, 4 types data: patient id, whether repeat patient, question asked, response.250 observations rows data patient 5 rows data (one per question) 50 patients (50 * 5 = 250).","code":"\nstr(wide1)\nsummary(wide1)\nhead(wide1)"},{"path":"tidy.html","id":"tidy-1","chapter":"3 Data Tidying","heading":"3.8.2 Tidy 1","text":"Transform wide1 long-form using pivot_longer() store object named tidy1","code":"\ntidy1 <- wide1 %>%\n  pivot_longer(cols = q1:q5,\n               names_to = \"question\", \n               values_to = \"response\")"},{"path":"tidy.html","id":"survey-2","chapter":"3 Data Tidying","heading":"3.8.3 Survey 2","text":"wide2 also data 50 patients, however, now two measures included questionnaire. still five questions relate satisfaction, also five questions relate whether patient recommend medical practice friend. measures typically reported calculating overall mean five items.Use method choice look dataset familiarize structure data.simple first exercise actually two potential ways might tidy data, depending want conceptualize two different measurements. important recognize many coding problems just one solution.","code":""},{"path":"tidy.html","id":"tidy-2a","chapter":"3 Data Tidying","heading":"3.8.3.1 Tidy 2a","text":"first option, going treat \"satisfaction\" \"recommendation\" measurements two categories variable. fully long-form data set five variables id, repeat_patient, question (question number), category (whether sat rec), response (numerical rating).many observations fully long-form version wide2 ? 500 rows data participant 10 rows: 5 satisfaction questions five recommendation questions.Transform wide2 full long-form using pivot_longer() store object named tidy2a.data %>% pivot_longer()names_to  = c(\"col1\", \"col2\")","code":"\ntidy2a <- wide2 %>%\n  pivot_longer(cols = q1_sat:q5_rec,\n               names_to = c(\"question\", \"category\"), \n               names_sep = \"_\",\n               values_to = \"response\")"},{"path":"tidy.html","id":"tidy-2b","chapter":"3 Data Tidying","heading":"3.8.3.2 Tidy 2b","text":"second option treat satisfaction recommendation scores two distinct variables. makes sense satisfaction recommendation scores question number related (e.g., q1 thing questions), making part observation.version also five variables, fully long-form, 'll slight mix two going call \"semi-long\". variables semi-long version id, repeat, question (question number), sat (response satisfaction question), rec (response recommendation question).many observations semi-long version wide2 ? 250 rows data , just like tidy1, participant 5 rows, one five questions. different responses satisfaction recommendation questions different variables.take multiple steps - can create different objects use pipeline.can reuse code tidy2a, just need add extra line makes data slightly wider.data %>% pivot_longer() %>% pivot_wider()","code":"\ntidy2b <- wide2 %>%\n  pivot_longer(cols = q1_sat:q5_rec,\n               names_to = c(\"question\", \"category\"), \n               names_sep = \"_\",\n               values_to = \"response\") %>%\n  pivot_wider(names_from = \"category\", values_from = \"response\")"},{"path":"tidy.html","id":"analysis-and-visualisation","chapter":"3 Data Tidying","heading":"3.8.4 Analysis and visualisation","text":"Using group_by() summarise(), calculate mean score participant satisfaction recommendation. versions dataset can see structure dataset changes approach need take.Replicate following:","code":"\ntidy2a %>%\n  group_by(id, category) %>%\n  summarise(mean = mean(response))\n\ntidy2b %>%\n  group_by(id) %>%\n  summarise(mean_satisfaction = mean(sat),\n            mean_rec = mean(rec))"},{"path":"tidy.html","id":"plot-1","chapter":"3 Data Tidying","heading":"3.8.4.1 Plot 1","text":"Scatterplot showing relationship satisfaction recommendation scores, whether patient repeat patient.geom_jitter()","code":"\nggplot(tidy2b, aes(x = sat, y = rec, colour = repeat_patient)) +\n  geom_jitter() +\n  geom_smooth(method = \"lm\") +\n  labs(x = \"Satisfaction score\", y = \"Recommendation score\", title = \"Satisfaction and recommendation scores\") +\n  theme_minimal()"},{"path":"tidy.html","id":"plot-2","chapter":"3 Data Tidying","heading":"3.8.4.2 Plot 2","text":"Boxplots showing satisfaction recommends scores new repeat patients separately.","code":"\nggplot(tidy2a, aes(x = repeat_patient, y = response, fill = repeat_patient)) +\n  geom_boxplot(show.legend = FALSE) +\n  facet_wrap(~category)+\n  theme_bw() +\n  scale_fill_brewer(palette = \"Dark2\")"},{"path":"tidy.html","id":"plot-3","chapter":"3 Data Tidying","heading":"3.8.4.3 Plot 3","text":"Histogram showing distribution responses, across questions categories.","code":"\nggplot(tidy2a, aes(x = response)) +\n  geom_histogram(binwidth = 1, colour = \"black\", fill = \"Grey\") +\n  labs(x = \"Responses across all questions and categories\") +\n  theme_bw()"},{"path":"tidy.html","id":"your-data","chapter":"3 Data Tidying","heading":"3.8.5 Your data","text":"wide-form dataset , try tidy long-form get stuck just want check solution, post Us Research Academy Help Discussion forum - just remember careful sharing confidential data dataset.head hurts bit point, rest assured absolutely normal. said start, reshaping tidying data conceptual leap shortcut fact just takes bit time practice different data sets - get eventually!","code":""},{"path":"tidy.html","id":"glossary-tidy","chapter":"3 Data Tidying","heading":"3.9 Glossary","text":"","code":""},{"path":"tidy.html","id":"resources-tidy","chapter":"3 Data Tidying","heading":"3.10 Further resources","text":"Data tidying cheat sheetTidy DataChapter 12: Tidy Data R Data ScienceChapter 18: Pipes R Data Science","code":""},{"path":"live-office-hour-1.html","id":"live-office-hour-1","chapter":"4 Live Office Hour 1","heading":"4 Live Office Hour 1","text":"","code":""},{"path":"live-office-hour-1.html","id":"schedule-and-zoom-link","chapter":"4 Live Office Hour 1","heading":"4.1 Schedule and Zoom link","text":"first live office hour session take place Tuesday 21st Feb 4pm â€“ 5pm EST via Zoom.password 633989 waiting room enabled. Please ensure Zoom name set name used register Us Researcher Academy otherwise may allowed entry session.","code":""},{"path":"live-office-hour-1.html","id":"content","chapter":"4 Live Office Hour 1","heading":"4.2 Content","text":"Live office hours primarily opportunity ask questions instructors, get support problems , request additional information aspect course far.Emily lead Q&session material covered workbook Week 1Javan lead Q&session skills learned transfer Us Researcher Workbench.","code":""},{"path":"live-office-hour-1.html","id":"pre-requisites","chapter":"4 Live Office Hour 1","heading":"4.3 Pre-requisites","text":"joining office hour, please ensure worked material Week 1 - consult Progress Tracker sure need .can ask questions day, can also complete Q&form advance let instructors know like session focus .","code":""},{"path":"analysis1.html","id":"analysis1","chapter":"5 Comparing Means","heading":"5 Comparing Means","text":"","code":""},{"path":"analysis1.html","id":"ilo-analysis","chapter":"5 Comparing Means","heading":"5.1 Intended Learning Outcomes","text":"end chapter able :Perform one-sample, independent, paired-samples t-testsPerform one-way factorial ANOVAs post-hoc comparisonsPerform non-parametric two-group comparisonsThe following two chapters give whistle-stop tour basic common statistical tests perform R. Importantly, statistics course, programming course, going go detail theory behind statistical test use . included links number excellent statistic resources Resources section like deeper dive.chapters likely cause less trouble data wrangling tidying comes R (programming language really), analyzing data generally much easier getting data right format analysis. reason, chapter also contain little bit wrangling tidying help consolidate links tasks analyses might need .","code":""},{"path":"analysis1.html","id":"walkthrough-analysis","chapter":"5 Comparing Means","heading":"5.2 Walkthrough video","text":"encourage read workbook attempt step watching video help consolidate learning (may feel harder making mistakes informative help learn long-run).","code":""},{"path":"analysis1.html","id":"setup-analysis1","chapter":"5 Comparing Means","heading":"5.3 Set-up","text":"Create save new R Markdown document named chapter_5.Rmd, get rid default template text line 11 onwards.Add code set-chunk run code load packages data.may need install packages installed already.","code":"\nlibrary(tidyverse)   \nlibrary(broom)\nlibrary(afex)\nlibrary(emmeans)\nlibrary(gapminder)\nlibrary(medicaldata)\ndata(\"polyps\")\ndata(\"gapminder\")\ndata(\"laryngoscope\")"},{"path":"analysis1.html","id":"comparing-two-means","chapter":"5 Comparing Means","heading":"5.4 Comparing two means","text":"going use polyps dataset run number different t-tests. may find useful familiarize dataset proceeding . first step, create new variable reduction difference number polyps baseline compared 12 months treatment began - higher number reflects greater reduction polpys (.e., positive number good thing). Additionally, avoid issues, also just going use complete dataset, include participants data time-points.","code":"\npolyps <- polyps %>%\n  drop_na(number12m) %>% # drop missing values\n  mutate(reduction = baseline - number12m)"},{"path":"analysis1.html","id":"one-sample-t-test","chapter":"5 Comparing Means","heading":"5.4.1 One-sample t-test","text":"can perform one-sample t-test new reduction variable determine whether reduction polyps treatment significantly different zero.First, visualize data using simple boxplot. got one, set x variable x = \"\".visualization makes clear couple outliers data. arguments whether retain remove values; get theoretical weeds, just show code option.mu true value mean, .e., value want compare data toalternative specifies direction alternative hypothesis, can choose two.sided, greater, less. set test greater reasonable hypothesize reduction polyps treatment zero.function tidy() comes broom package takes somewhat messy output produced base R functions tidies table easier work .conf.high displayed Inf specified one-tailed test.significant difference number polyps treatment according test, course, included data control treatment group analysis.can use function () combined group_by() perform test different groups. example, can run one-sample t-test treatment groups separately see reduction polyps significantly different zero sulindac condition.","code":"\nggplot(polyps, aes(x = \"\", y = reduction)) +\n  geom_boxplot() +\n  labs(x = NULL, y = \"Reduction in polyps\")\n# keep the outliers, i.e., use the full dataset as is\nt.test(x = polyps$reduction,\n       mu = 0,\n       alternative = \"greater\")%>%\n  tidy()\n# remove the outliers\n\npolyps_outliers <- polyps %>%\n  filter(reduction < 100) # keep only those values less than 100\n\nt.test(x = polyps_outliers$reduction, \n       mu = 0,\n       alternative = \"greater\")%>%\n  tidy()\npolyps_outliers %>% \n  group_by(treatment) %>%\n  do(                               \n    t.test(.$reduction, # the . replaces the name of the dataset because we've used a pipe\n           mu = 0,\n           alternative = \"greater\") %>%  \n      tidy()                        \n  )"},{"path":"analysis1.html","id":"independent-samples-t-test","chapter":"5 Comparing Means","heading":"5.4.2 Independent samples t-test","text":"t.test() function can used perform types t-tests, just need include different arguments. example, conduct independent t-test determine whether reduction polyps significantly different two groups.First, visualize difference using violin-boxplot (try running plot original dataset polyps see difference removing outliers makes):Now run t-test, using t.test():two different ways specifying variables, can use object$variable notation specify dataset. entirely personal preference one use.alternative = \"greater\" alternative x larger mean y. x first level grouping variable y second. case, placebo first group sulindac second, hypothesize treatment group higher reduction placebo group, actually need specify less, hypothesis first group lower mean second group. regularly breaks brain.var.equal whether variances two groups equal. set TRUE, test performed standard Student's independent t-test. set FALSE (default R case stats programs), run Welch t-test (see paper Delacre et al. argues Welch test default)","code":"\nggplot(polyps_outliers, aes(x = treatment, y = reduction)) +\n  geom_violin() +\n  geom_boxplot(width = .2) +\n  geom_jitter(alpha = .7, width = .1, aes(colour = treatment)) +\n  theme_minimal() +\n  guides(color = \"none\")\n# specify data set \nt.test(reduction ~ treatment, \n       data = polyps_outliers,\n       alternative = \"less\",\n       var.equal = TRUE) %>% \n  tidy()\n\n# call variables\nt.test(polyps_outliers$reduction ~ polyps_outliers$treatment, \n       alternative = \"less\",\n       var.equal = TRUE) %>% \n  tidy()"},{"path":"analysis1.html","id":"paired-samples-t-test","chapter":"5 Comparing Means","heading":"5.4.3 Paired-samples t-test","text":"paired-samples t-test throws first real need data wrangling. take quick detour use gampinder dataset (take moment familiarize dataset using help documentation). gapminder dataset tidy format: country multiple rows data, one year dataset. means easy conduct paired-samples t-test. example, compare life expectancy 1997 2007.always, visualize first:Well look right . issue year coded numeric variable tried create plot requires categorical variable x-axis. order get plot work, need change year factor:better.Now can run t-test look life expectancy 1997 2007 collapsing across countries:use group_by() () split continent:run multiple tests, might also want add column p-values corrected multiple comparisons, tidy table whilst .use select() just retain columns want, rename time.mutate() adds new column using function p.adjust calculate adjusted p-value. can specify multiple different methods - full details via help documentation. Importantly, order work, include ungroup() first, otherwise p.adjust performed groups (.e., consider , entire point).Now seen paired-samples test works,return polyps dataset. problem dataset wide-form order run test need grouping variable (time point) one column measurement (number polyps separate column). Therefore, order run t-test, first need tidy dataset chapter 3.can run paired t-test tidied data. take time practice different datasets learn need reshape data analysis get !","code":"\ngapminder %>%\n  filter(year %in% c(1997, 2007)) %>% # just pull out the two years we're interested in\n  ggplot(aes(x = year, y = lifeExp)) +\n  geom_violin() +\n  geom_boxplot(width = .2)## Warning: Continuous x aesthetic\n## i did you forget `aes(group = ...)`?\ngapminder <- gapminder %>%\n  mutate(year = as.factor(year))\ngapminder %>%\n  filter(year %in% c(1997, 2007)) %>% \n  ggplot(aes(x = year, y = lifeExp)) +\n  geom_violin() +\n  geom_boxplot(width = .2)\ngapminder %>%\n  filter(year %in% c(1997, 2007)) %>% \n  t.test(lifeExp ~ year, \n         data = ., # the . replaces the dataset because we've piped in the data\n         paired = TRUE) %>%\n  tidy()\ngapminder %>%\n  filter(year %in% c(1997, 2007)) %>% \n  group_by(continent) %>%\n  do(                               \n    t.test(lifeExp ~ year, \n           data = .,\n           alternative = \"less\",\n           paired = TRUE) %>%  \n      tidy()                        \n  )\ngapminder %>%\n  filter(year %in% c(1997, 2007)) %>% \n  group_by(continent) %>%\n  do(                               \n    t.test(lifeExp ~ year, \n           data = .,\n           paired = TRUE) %>%  \n      tidy()                        \n  ) %>%\n  select(continent, \n         \"lifeExp_diff\" = estimate,\n         p.value,\n         \"df\" = parameter,\n         conf.low, \n         conf.high) %>%\n  ungroup() %>%\n  mutate(p.adjusted = p.adjust(p.value, method = \"bonferroni\"))\npolyps_tidy <- polyps_outliers %>%\n  pivot_longer(cols = c(\"baseline\", \"number3m\", \"number12m\"), # columns to make long \n               names_to = \"time\", # new column name for headers\n               values_to = \"polyps_n\") # new column name for values\npolyps_tidy %>%\n  filter(time %in% c(\"baseline\", \"number12m\")) %>%\n  t.test(polyps_n ~ time, data = ., paired = TRUE) %>%\n  tidy()"},{"path":"analysis1.html","id":"comparing-more-than-two-means","chapter":"5 Comparing Means","heading":"5.5 Comparing more than two means","text":"often two means compare. One approach use Analysis Variance (ANOVA) techniques. numerous ways perform ANOVA R, course, going use afex package just aware Google help, might see different approaches.","code":""},{"path":"analysis1.html","id":"one-way-anova","chapter":"5 Comparing Means","heading":"5.5.1 One-way ANOVA","text":"use gapminder dataset look life expectancy continent 2007. First, create object just data need visualize .looks like significant difference groups. run ANOVA, use aov_ez() function afex package.Just like t-tests, can use tidy() make output easier work .Run code transform output. worry warning message, just telling know automatically rename columns keep original names.run post-hoc tests groups, use emmeans function emmeans package. function computes possible pairwise comparison t-tests applies correction p-value.","code":"\n# filter the data to just 2007 values\ngapminder_2007 <- gapminder %>%\n  filter(year == 2007)\n\n# visualize with a boxplot\nggplot(gapminder_2007, aes(x = continent, y = lifeExp, fill = continent)) +\n  geom_boxplot(alpha = .6) +\n  scale_fill_viridis_d(option = \"E\") +\n  guides(fill = \"none\") +\n  theme_minimal() \nlifeExp_anova <- aov_ez(id = \"country\", #unique identifier in this case, country name\n       dv = \"lifeExp\",\n       between = \"continent\",\n       es = \"pes\", # desired effect size, set to partial eta squared\n       type = 3, # type of sums of squares to use\n       include_aov = TRUE, # set to true to allow post hoc-comparisons\n       data = gapminder_2007) ## Contrasts set to contr.sum for the following variables: continent\nlifeExp_anova$anova_table %>% tidy()## Warning in tidy.anova(.): The following column names in ANOVA output were not\n## recognized or transformed: num.Df, den.Df, MSE, ges\n# calculate the comparisons\nposthoc <-emmeans(lifeExp_anova, pairwise ~ continent, adjust = \"bonferroni\")\n\n# pull out the table of comparisons and tidy it up into a table\nposthoc_contrasts <- posthoc$contrasts %>% tidy()"},{"path":"analysis1.html","id":"factorial-anova","chapter":"5 Comparing Means","heading":"5.5.2 Factorial ANOVA","text":"Factorial ANOVAs can also specified using functions. example, gapminder dataset run mixed two-way ANOVA looking life expectancy continent year. start creating object data need visualizing :run ANOVA. code much one-way variant addition within argument represent repeated-measures variable. multiple within subject variables, specify = c(\"var1\", \"var2\").interaction significant although main effects can run post-hoc tests find differences (ignore already know one-way ANOVA just ):Whilst strictly appropriate given interaction significant, wanted look pairwise comparisons interaction effect, use notation pairwise ~ IV1 | IV2:Note two factors, also reverse order IVs. , get results contrasting 2002 2007 continent. Instead, look difference continents year.Run code look output contrast_factorial contrasts_factorial2 carefully making sure understand interpret results. find useful refer interaction plot made earlier.","code":"\n# create a subset of the data with filter\ngapminder_noughties <- gapminder %>%\n  filter(year %in% c(2002, 2007))\n\n# visualize the data\n\nggplot(gapminder_noughties, aes(x = continent, y = lifeExp, color = year, group = year)) +\n  geom_jitter(alpha = .2, width = .1) +\n  stat_summary(geom = \"point\", fun = \"mean\", size = 2) +\n  stat_summary(geom = \"line\", fun = \"mean\") +\n  theme_minimal() +\n  scale_colour_brewer(palette = \"Dark2\")\nlifeExp_year <- aov_ez(id = \"country\", \n       dv = \"lifeExp\",\n       between = \"continent\",\n       within = \"year\",\n       es = \"pes\", # desired effect size, set to partial eta squared\n       type = 3, # type of sums of squares to use\n       include_aov = TRUE, # set to true to allow post hoc-comparisons\n       data = gapminder_noughties) ## Contrasts set to contr.sum for the following variables: continent\nlifeExp_year$anova_table %>% tidy()## Warning in tidy.anova(.): The following column names in ANOVA output were not\n## recognized or transformed: num.Df, den.Df, MSE, ges\n# perform contrasts for the main effect of year\nposthoc_year <- emmeans(lifeExp_year, \n                             pairwise ~ year, \n                             adjust = \"bonferroni\")\n\ncontrasts_year <- posthoc_year$contrasts %>%\n  tidy()\n\n# perform contrasts for the main effect of continent\nposthoc_continent <- emmeans(lifeExp_year, \n                             pairwise ~ continent, \n                             adjust = \"bonferroni\")\n\ncontrasts_continent <- posthoc_continent$contrasts %>%\n  tidy()\n# run the tests\nposthoc_factorial <- emmeans(lifeExp_year, \n                             pairwise ~ year| continent, \n                             adjust = \"bonferroni\")\n\n# tidy up the output of the tests\ncontrasts_factorial <- posthoc_factorial$contrasts %>%\n  tidy()\n# run the tests\nposthoc_reversed <- emmeans(lifeExp_year, \n                             pairwise ~ continent| year, \n                             adjust = \"bonferroni\")\n\n# tidy up the output of the tests\ncontrasts_reversed <- posthoc_reversed$contrasts %>%\n  tidy()"},{"path":"analysis1.html","id":"non-parametric-options","chapter":"5 Comparing Means","heading":"5.6 Non-parametric options","text":"Finally, may also need compare groups data non-parametric. might violate assumption normality linearity, working ordinal data , example, Likert scales.polyps dataset, one option (particularly sophisticated option admit suffice showing code) might conduct Wilcoxon Rank Sum test (also known Mann-Whitney U test) reduction variable data transformed ranks.Performing test produce warning able compute exact p-values ties data (, one data point rank) instead approximation used. like deep dive maths behind , might find Stack Overflow thread helpful.function can used repeated-measures Wilcoxon Signed Ranks test:","code":"\nwilcox.test(reduction ~ treatment, \n            data = polyps) %>% \n  tidy()## Warning in wilcox.test.default(x = c(14, -23, -26, 5, -8, 274, -8, 1, -16, :\n## cannot compute exact p-value with ties\npolyps_tidy %>%\n  filter(time %in% c(\"baseline\", \"number12m\")) %>%\n  wilcox.test(polyps_n ~ treatment, \n            data = .) %>% \n  tidy()## Warning in wilcox.test.default(x = c(77, 63, 5, 28, 35, 61, 12, 7, 7, 15, :\n## cannot compute exact p-value with ties"},{"path":"analysis1.html","id":"resources-analysis1","chapter":"5 Comparing Means","heading":"5.7 Further resources","text":"noted, statistics course purpose deep dive statistical tests theory. Instead, aim provide basic overview statistical analysis R basics, coding need use complex additional tests similar. completed course recommend consulting specific statistical resources help guide analyses want conduct.Learning statistics R Danielle NavarroLearning statistical models simulation RR health data scienceIntroduction Modern StatisticsStatistical inference via data science","code":""},{"path":"analysis2.html","id":"analysis2","chapter":"6 Correlation and Regression","heading":"6 Correlation and Regression","text":"","code":""},{"path":"analysis2.html","id":"ilo-analysis2","chapter":"6 Correlation and Regression","heading":"6.1 Intended Learning Outcomes","text":"end chapter able :Perform visualize Pearson Spearman correlationsConstruct simple multiple linear logistic regression modelsAs Comparing Means, chapter unlikely cover everything want know regression, particularly use advanced techniques research. Instead, give basic coding skills need understand models constructed programming perspective, point towards additional resources heavier focus statistical theory.","code":""},{"path":"analysis2.html","id":"walkthrough-analysis2","chapter":"6 Correlation and Regression","heading":"6.2 Walkthrough video","text":"encourage read workbook attempt step watching video help consolidate learning (may feel harder making mistakes informative help learn long-run).","code":""},{"path":"analysis2.html","id":"setup-analysis2","chapter":"6 Correlation and Regression","heading":"6.3 Set-up","text":"Create save new R Markdown document named chapter_6.Rmd, get rid default template text line 11 onwards.Add code set-chunk run code load packages data.may need install packages installed already.","code":"\nlibrary(tidyverse)   \nlibrary(broom)\nlibrary(psych)\nlibrary(easystats)\nlibrary(gapminder)\nlibrary(medicaldata)\ndata(\"polyps\")\ndata(\"opt\")\ndata(\"gapminder\")"},{"path":"analysis2.html","id":"correlation","chapter":"6 Correlation and Regression","heading":"6.4 Correlation","text":"ANOVA, huge number packages functions can use perform correlations. course, going use correlation package part easystats framework tries provide unifying framework analysis similar tidyverse collection packages data wrangling visualization.jumping different datasets best fit analysis technique demonstrating take time familiarize variables get started.First, use gapminder dataset look relationship life expectancy GDP per capita Americas. good measure first calculate descriptive statistics two variables progress looking relationship . Rather use summarise(), use describe() function psych package easily produces range descriptive stats:can visualize relationship:can see quite clear relationship life expectancy GDP, however, can also see scatterplot skew stats linear relationship, GDP positively skewed, fact becomes even clearer visualize GDP histogram:different approaches dealing skew, show two options available addition researching different theoretical approaches, worth looking help documentation analysis function see options advanced analysis techniques. First, conduct Spearman's correlation suitable non-linear relationships transforms data ranks.correlation() function easystats correlation package nice function performing correlations. contain huge number options types correlation analysis (look help documentation), built work well tidyverse means can pipe output produces already tidy:may also wish apply log transformation GDP data. fix skew potentially appropriate look relationship relative differences GDP rather absolute. can produce log transformation using functions mutate() log()","code":"\ndescriptives <- gapminder %>%\n  filter(continent == \"Americas\") %>%\n  select(lifeExp, gdpPercap) %>%\n  describe()\ngapminder %>%\n  filter(continent == \"Americas\") %>%\n  ggplot(aes(x = lifeExp, y = gdpPercap)) +\n  geom_point() +\n  geom_smooth()## `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\ngapminder %>%\n  filter(continent == \"Americas\") %>%\n  ggplot(aes(x = gdpPercap)) +\n  geom_histogram()## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\nspearman_results <- gapminder %>%\n  filter(continent == \"Americas\") %>%\n  correlation(select = \"lifeExp\", select2 = \"gdpPercap\", method = \"spearman\")\n\nspearman_results\ngapminder <- gapminder %>%\n  mutate(gdp_log = log10(gdpPercap))\n\n# histogram of log transformed GDP\ngapminder %>%\n  filter(continent == \"Americas\") %>%\n  ggplot(aes(x = gdp_log)) +\n  geom_histogram()\n\n# scatteplot of log GDP and life expectancy\ngapminder %>%\n  filter(continent == \"Americas\") %>%\n  ggplot(aes(x = lifeExp, y = gdp_log)) +\n  geom_point() +\n  geom_smooth() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n## `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\npearson_results <- gapminder %>%\n  filter(continent == \"Americas\") %>%\n  correlation(select = \"lifeExp\", select2 = \"gdpPercap\", method = \"pearson\")\n\npearson_results"},{"path":"analysis2.html","id":"regression","chapter":"6 Correlation and Regression","heading":"6.5 Regression","text":"","code":""},{"path":"analysis2.html","id":"linear-regression","chapter":"6 Correlation and Regression","heading":"6.5.1 Linear regression","text":"Constructing regression model great example fact comes R, data cleaning wrangling far difficult task face. construct simple linear regression model use function lm() (linear model):formula expressed outcome predictor case, predicting life expectancy GDPWe use notation data = . piping filtered dataset function. wanted run regression full dataset, remove first two lines pipes just data = gapminderlm() constructs model whilst summary() summarizes results.can also pass model summary tidy() pass model stats tidy table:looks like significant model GDP predicts life expectancy. probably shock anyone check use linear model really appropriate assessing model performance.","code":"\nmod1 <- gapminder %>%\n  filter(continent == \"Americas\") %>%\n  lm(formula = lifeExp ~ gdp_log, data = .)\n\nsummary(mod1)## \n## Call:\n## lm(formula = lifeExp ~ gdp_log, data = .)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -17.221  -4.761   1.184   4.736  15.006 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  -19.068      4.824  -3.953 9.65e-05 ***\n## gdp_log       22.377      1.285  17.412  < 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 6.591 on 298 degrees of freedom\n## Multiple R-squared:  0.5043, Adjusted R-squared:  0.5026 \n## F-statistic: 303.2 on 1 and 298 DF,  p-value: < 2.2e-16\nsummary(mod1) %>%\n  tidy()"},{"path":"analysis2.html","id":"model-performance","chapter":"6 Correlation and Regression","heading":"6.5.2 Model performance","text":"performancee package also part easystats framework provides number elegant simple functions assessing model performance. use type modelling research, strongly recommended checking performance help documentation website information can .can test assumptions model separately using functions like check_heteroscedasticity(), however, single comprehensive function check_model() provides overview:**get error Error: RStudio 'Plots' window small show set plots. Please make window larger. literally resize bottom right window pane dragging cursor re-run code.perfect, can still see influence skew, good enough leave -depth theoretical debates model performance statisticians!","code":"\ncheck_model(mod1)"},{"path":"analysis2.html","id":"multiple-regression","chapter":"6 Correlation and Regression","heading":"6.5.3 Multiple regression","text":"Adding additional variables regression model extremely simple. analysis, use polyps dataset , remove extreme outliers. time, going construct model see can predict number polyps 12 months function baseline number polyps (reasonable assume people baseline high number polyps going polyps treatment started low number, even treatment successful) treatment group .First, visualize relationship.Now, construct summarize model adding two predictors:want specify interaction term, can using notation predictor1:predictor2:","code":"\npolyps_outliers <- polyps %>%\n  filter(baseline < 100) # keep only those values less than 100\n\npolyps_outliers %>%\n  ggplot(aes(x = baseline, y = number12m, colour = treatment)) +\n  geom_point() +\n  geom_smooth(method =\"lm\")## `geom_smooth()` using formula = 'y ~ x'## Warning: Removed 2 rows containing non-finite values (`stat_smooth()`).## Warning: Removed 2 rows containing missing values (`geom_point()`).\nmod2 <-lm(number12m ~ baseline + treatment, data = polyps_outliers)\nsummary(mod2)## \n## Call:\n## lm(formula = number12m ~ baseline + treatment, data = polyps_outliers)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -16.1177  -7.6670  -0.9539   6.7388  20.5473 \n## \n## Coefficients:\n##                   Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)        14.0733     5.1018   2.759  0.01463 *  \n## baseline            0.7537     0.1421   5.305 8.82e-05 ***\n## treatmentsulindac -17.8498     5.2023  -3.431  0.00371 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 10.37 on 15 degrees of freedom\n##   (2 observations deleted due to missingness)\n## Multiple R-squared:  0.794,  Adjusted R-squared:  0.7665 \n## F-statistic:  28.9 on 2 and 15 DF,  p-value: 7.156e-06\nmod3 <-lm(number12m ~ baseline + treatment + baseline:treatment, data = polyps_outliers)\nsummary(mod3)## \n## Call:\n## lm(formula = number12m ~ baseline + treatment + baseline:treatment, \n##     data = polyps_outliers)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -16.7752  -6.5608   0.4709   4.6696  20.8654 \n## \n## Coefficients:\n##                            Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)                 15.2399     5.3496   2.849 0.012881 *  \n## baseline                     0.7113     0.1526   4.660 0.000368 ***\n## treatmentsulindac          -24.1491     9.2957  -2.598 0.021064 *  \n## baseline:treatmentsulindac   0.3709     0.4513   0.822 0.424934    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 10.49 on 14 degrees of freedom\n##   (2 observations deleted due to missingness)\n## Multiple R-squared:  0.8034, Adjusted R-squared:  0.7613 \n## F-statistic: 19.08 on 3 and 14 DF,  p-value: 3.241e-05"},{"path":"analysis2.html","id":"prediction","chapter":"6 Correlation and Regression","heading":"6.5.4 Prediction","text":"constructed models, can model predict new values. example, create table data new patients baseline number polyps treatment condition due receive.can use mutate() predict() create new variable predicted_12m uses model constructed mod2 predict many polyps number patients 12 months, taking account baseline treatment group. Note order predict() function work, need data predictors entered original model (case baseline treatment).","code":"\nnew_patients <- tibble(\n  participant_id = 1:10,\n  baseline = c(20, 25, 30, 35, 40, 45, 50, 55, 60, 65),\n  treatment = c(\"sulindac\", \"placebo\", \"sulindac\", \"placebo\", \"sulindac\", \"placebo\", \"sulindac\", \"placebo\", \"sulindac\", \"placebo\")\n)\nnew_patients <- new_patients %>%\n  mutate(predicted_12m = predict(mod2, new_patients))\n\nnew_patients"},{"path":"analysis2.html","id":"logistic-regression","chapter":"6 Correlation and Regression","heading":"6.5.5 Logistic regression","text":"Constructing logistic regression model follows similar syntax uses function glm() (generalized linear model) rather lm() used previously. model, use opt dataset see can predict whether patient chlamydia. First, create reduced dataset variable want include model check variables:summary output reveals interesting quick dataset.missing data chlamydia Hisp variables represent missing value instead, coded blank inexplicably actually blank, R thinks type data cell otherwise show NA.deal either convert blanks NAs. dataset badly coded took several attempts trial--error figure blank - turns three spaces also \"\" stored \"\" space . need outcome binary variable, can use droplevels get rid blank grouping (try removing call droplevels run summary() see data represented).can construct summarize model using glm() summary() tells us significant predictor chlamydia measures included age:","code":"\nchlamydia_dat <- opt %>%\n  select(PID, Age, Black, White,Nat.Am, Asian, Hisp, Education, Chlamydia) \n\nsummary(chlamydia_dat)##       PID              Age        Black     White     Nat.Am    Asian    \n##  Min.   :100034   Min.   :16.00   No :451   No :588   No :573   No :816  \n##  1st Qu.:200501   1st Qu.:22.00   Yes:372   Yes:235   Yes:250   Yes:  7  \n##  Median :202717   Median :25.00                                          \n##  Mean   :252541   Mean   :25.98                                          \n##  3rd Qu.:302208   3rd Qu.:30.00                                          \n##  Max.   :402477   Max.   :44.00                                          \n##   Hisp         Education   Chlamydia\n##     :145   8-12 yrs :479      :444  \n##  No :328   LT 8 yrs :154   No :324  \n##  Yes:350   MT 12 yrs:190   Yes: 55  \n##                                     \n##                                     \n## \nchlamydia_dat2 <- chlamydia_dat %>%\n  mutate(Chlamydia = na_if(Chlamydia, \"   \"),\n         Hisp = na_if(Hisp, \"   \")) %>%\n  droplevels()\n\nsummary(chlamydia_dat2)##       PID              Age        Black     White     Nat.Am    Asian    \n##  Min.   :100034   Min.   :16.00   No :451   No :588   No :573   No :816  \n##  1st Qu.:200501   1st Qu.:22.00   Yes:372   Yes:235   Yes:250   Yes:  7  \n##  Median :202717   Median :25.00                                          \n##  Mean   :252541   Mean   :25.98                                          \n##  3rd Qu.:302208   3rd Qu.:30.00                                          \n##  Max.   :402477   Max.   :44.00                                          \n##    Hisp         Education   Chlamydia \n##  No  :328   8-12 yrs :479   No  :324  \n##  Yes :350   LT 8 yrs :154   Yes : 55  \n##  NA's:145   MT 12 yrs:190   NA's:444  \n##                                       \n##                                       \n## \nlog_mod1 <- glm(formula = Chlamydia ~ Age + Black + White + Nat.Am + Asian + Hisp + Education, family = binomial, data = chlamydia_dat2)\n\nsummary(log_mod1)## \n## Call:\n## glm(formula = Chlamydia ~ Age + Black + White + Nat.Am + Asian + \n##     Hisp + Education, family = binomial, data = chlamydia_dat2)\n## \n## Deviance Residuals: \n##     Min       1Q   Median       3Q      Max  \n## -0.9148  -0.5964  -0.4600  -0.2546   2.6650  \n## \n## Coefficients:\n##                     Estimate Std. Error z value Pr(>|z|)   \n## (Intercept)          0.14010    1.37969   0.102  0.91912   \n## Age                 -0.10035    0.03870  -2.593  0.00951 **\n## BlackYes             0.91122    1.03929   0.877  0.38061   \n## WhiteYes             0.49145    0.93914   0.523  0.60077   \n## Nat.AmYes            0.04426    1.03917   0.043  0.96602   \n## AsianYes           -12.59871  882.74399  -0.014  0.98861   \n## HispYes             -0.09363    0.69314  -0.135  0.89255   \n## EducationLT 8 yrs   -1.08588    0.78482  -1.384  0.16648   \n## EducationMT 12 yrs   0.16801    0.41405   0.406  0.68491   \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 246.23  on 310  degrees of freedom\n## Residual deviance: 224.21  on 302  degrees of freedom\n##   (512 observations deleted due to missingness)\n## AIC: 242.21\n## \n## Number of Fisher Scoring iterations: 13"},{"path":"analysis2.html","id":"resources-analysis1","chapter":"6 Correlation and Regression","heading":"6.6 Further resources","text":"much can R comes analysis techniques claim even begun scratch surface . important coding perspective, now programming skill knowledge need extend expand analytic workflows R: , statistical theory knowledge take (course stops , Emily knows limits).specific analytic techniques like use R, please let us know ahead second office hour collate extra resources specific needs help support goals Javan also answer questions analytic techniques using Us Researcher Workbench.easystatsLearning statistics R Danielle NavarroLearning statistical models simulation RR health data scienceIntroduction Modern StatisticsStatistical inference via data science","code":""},{"path":"live-office-hour-2.html","id":"live-office-hour-2","chapter":"7 Live Office Hour 2","heading":"7 Live Office Hour 2","text":"","code":""},{"path":"live-office-hour-2.html","id":"schedule-and-zoom-link-1","chapter":"7 Live Office Hour 2","heading":"7.1 Schedule and Zoom link","text":"second live office hour session take place Thursday 2nd March 4-5pm EST via Zoom.password 428447 waiting room enabled. Please ensure Zoom name set name used register Us Researcher Academy otherwise may allowed entry session.","code":""},{"path":"live-office-hour-2.html","id":"content-1","chapter":"7 Live Office Hour 2","heading":"7.2 Content","text":"Live office hours primarily opportunity ask questions instructors, get support problems , request additional information aspect course far.Emily lead Q&session material covered workbook Week 2Javan lead Q&session skills learned transfer Us Researcher Workbench.specific analytic techniques like use R covered, please let us know advance office hours via Q&form collate resources help support goals.","code":""},{"path":"live-office-hour-2.html","id":"pre-requisites-1","chapter":"7 Live Office Hour 2","heading":"7.3 Pre-requisites","text":"joining office hour, please ensure worked material Week 2 - consult Progress Tracker sure need .can ask questions day, can also complete Q&form advance let instructors know like session focus .","code":""},{"path":"completion-quiz.html","id":"completion-quiz","chapter":"8 Completion Quiz","heading":"8 Completion Quiz","text":"order receive recognition Us Researcher Academy completed course, required participate completion quiz.quiz 20 multiple-choice questions assess knowledge R.time limit.completion status based participation quiz, need achieve minimum score.Emily Nordmann access score names people participated quiz communicated RTI completion.can take quiz many times like.deadline completing quiz recognition Friday 17th March midnight.Access quiz via Google Forms.","code":""},{"path":"glossary.html","id":"glossary","chapter":"A Glossary","heading":"A Glossary","text":"can use glossary() function automatically link term psyTeachR glossary make project-specific glossary.create link glossary include tooltip short definition hover term. Use following syntax inline r: glossary(\"word\"). example, common data types integer, double, character.need link definition, using different form word, add display version second argument (display). can also override automatic short definition providing third argument (def). Add argument link = FALSE just want hover definition link psyTeachR glossary.[1] \"Data Types\"can add glossary table end chapter following code. creates table terms used chapter previous glossary_table() function. uses kableExtra(), use code chunk, set results='asis'.want contribute glossary, fork github project, add terms submit pull request, suggest new term issues page.","code":"\nglossary(\"data type\", \n         display = \"Data Types\", \n         def = \"My custom definition of data types\", \n         link = FALSE)```{r, echo=FALSE, results='asis'}\nglossary_table()```"},{"path":"license.html","id":"license","chapter":"License","heading":"License","text":"book licensed Creative Commons Attribution-ShareAlike 4.0 International License (CC--SA 4.0) using PsyTeachR book template (DeBruine, 2021). material book adapted following sources:Nordmann, E. & DeBruine, L. (2022) Applied Data Skills. v1.0. Retrieved https://psyteachr.github.io/ads-v1/ doi: 10.5281/zenodo.6365077Nordmann, E. & McAleer, P. (2021) Fundamentals Quantitative Analysis. v2.0. Retrieved https://psyteachr.github.io/quant-fun-v2/adapt material, must distribute contributions license original.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
